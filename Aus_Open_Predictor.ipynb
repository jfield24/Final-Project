{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.create_features_utils import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import models, layers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import metrics\n",
    "from keras.models import load_model\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/aus_open_matches_with_features.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df['diff_rank'] = df['player_0_rank'] - df['player_1_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = [\n",
    " 'diff_rank',\n",
    " 'diff_match_win_percent',\n",
    " 'diff_games_win_percent',\n",
    " 'diff_5_set_match_win_percent',\n",
    " 'diff_close_sets_percent',\n",
    " 'diff_match_win_percent_hard',\n",
    " 'diff_games_win_percent_hard',\n",
    " 'diff_5_set_match_win_percent_hard',\n",
    " 'diff_close_sets_percent_hard',\n",
    " 'diff_match_win_percent_60',\n",
    " 'diff_games_win_percent_60',\n",
    " 'diff_5_set_match_win_percent_60',\n",
    " 'diff_close_sets_percent_60',\n",
    " 'diff_match_win_percent_hard_100',\n",
    " 'diff_games_win_percent_hard_100',\n",
    " 'diff_5_set_match_win_percent_hard_100',\n",
    " 'diff_close_sets_percent_hard_100',\n",
    " 'diff_match_win_percent_hh',\n",
    " 'diff_games_win_percent_hh',\n",
    " 'diff_match_win_percent_hard_hh',\n",
    " 'diff_games_win_percent_hard_hh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.outcome\n",
    "features = df[features_list]\n",
    "\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.80425, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.80425 to 0.72055, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.72055\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.72055 to 0.60278, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.60278 to 0.53301, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.53301 to 0.52886, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.52886 to 0.51354, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.51354\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.51354 to 0.49767, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.49767 to 0.49765, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.49765 to 0.48956, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.48956\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.48956 to 0.48672, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.48672 to 0.48355, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.48355\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.48355 to 0.47864, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.47864\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.47864\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.47864 to 0.47652, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.47652 to 0.47376, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.47376\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.47376\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.47376\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.47376\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.47376 to 0.47325, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.47325\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.47325 to 0.47125, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.47125\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.47125\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.47125\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.47125\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.47125\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.47125\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.47125\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.47125 to 0.47045, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.47045 to 0.46994, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.46994\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.46994\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.46994 to 0.46852, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.46852\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.46852\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.46852\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.46852\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.46852\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.46852\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.46852\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.46852\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.46852\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.46852\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.46852\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.46852\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.46852\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.46852 to 0.46782, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.46782\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.46782\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.46782 to 0.46750, saving model to data\\best_model.h5\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.46750\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.46750\n"
     ]
    }
   ],
   "source": [
    "# Build the Neural Network\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(units=64, activation='relu', input_shape=(len(features.columns),)))\n",
    "network.add(layers.Dense(units=32, activation='relu'))\n",
    "network.add(layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "network.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=500)\n",
    "mc = ModelCheckpoint('data/best_model.h5', monitor='val_loss', mode='min', verbose=2, save_best_only=True)\n",
    "\n",
    "history = network.fit(train_features, train_target, \n",
    "            epochs=1000, verbose=0, batch_size=128, \n",
    "            validation_data=(test_features, test_target), callbacks=[es, mc]) \n",
    "\n",
    "saved_model = load_model('data/best_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.754, Test Accuracy: 0.807\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the best model\n",
    "_, train_acc = saved_model.evaluate(train_features, train_target, verbose=0)\n",
    "_, test_acc = saved_model.evaluate(test_features, test_target, verbose=0)\n",
    "\n",
    "print('Train Accuracy: %.3f, Test Accuracy: %.3f' % (train_acc, test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph train/test loss and accuracy\n",
    "plt.subplots(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Loss after each Epoch')\n",
    "plt.plot(history.epoch[::10], history.history['loss'][::10], label='Train')\n",
    "plt.plot(history.epoch[::10], history.history['val_loss'][::10], label='Test')\n",
    "plt.legend(['Train', 'Test'],loc='upper right', title='Sample', facecolor='white',fancybox=True)\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Epochs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy after each Epoch')\n",
    "plt.plot(history.epoch[::10], history.history['accuracy'][::10], label='Train')\n",
    "plt.plot(history.epoch[::10], history.history['val_accuracy'][::10], label='Test')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Epochs')\n",
    "plt.legend(['Train', 'Test'], loc='upper left', title='Sample', facecolor='white', fancybox=True)\n",
    "\n",
    "\n",
    "plt.savefig('data/loss_acc.jpg', quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.89       190\n",
      "           1       0.88      0.13      0.23        53\n",
      "\n",
      "    accuracy                           0.81       243\n",
      "   macro avg       0.84      0.56      0.56       243\n",
      "weighted avg       0.82      0.81      0.75       243\n",
      "\n",
      "[[189   1]\n",
      " [ 46   7]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\justi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Test data classification report and confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(test_target, saved_model.predict_classes(test_features)))\n",
    "print(confusion_matrix(test_target, saved_model.predict_classes(test_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86       722\n",
      "           1       0.61      0.10      0.17       248\n",
      "\n",
      "    accuracy                           0.75       970\n",
      "   macro avg       0.68      0.54      0.51       970\n",
      "weighted avg       0.72      0.75      0.68       970\n",
      "\n",
      "[[706  16]\n",
      " [223  25]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\justi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Trained data classification report and confusion matrix\n",
    "print(classification_report(train_target, saved_model.predict_classes(train_features)))\n",
    "print(confusion_matrix(train_target, saved_model.predict_classes(train_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
